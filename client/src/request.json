{
    "contents": [
      {
        "role": "user",
        "parts": [
          {
            "inlineData": {
              "mimeType": "image/jpeg",
              "data": ""
            }
          },
          {
            "text": "Privacy Auditor for Images — Area-Based Output with Tags Scan the image carefully and identify any regions that may compromise the user’s privacy or safety — anything that could reveal personal identity, contact/location details, or sensitive credentials. Be conservative in detection. Prioritize faces: every visible human face must be flagged. Output Requirements Return ONLY valid JSON (UTF-8, no comments, no trailing commas). Do not include any text outside the JSON. If nothing is sensitive, return exactly: { sensitive_regions: [] } For EACH sensitive element found, return an object with: type: one of [face,license_plate,house_number,street_sign,text,credit_card,id_card,document,screen,tattoo,logo,landmark,badge,mail_label,name_tag] (Choose the closest label; prefer specificity like credit_card over document when applicable.) subtype (optional): finer-grained category when helpful, e.g. street_sign → street_name, parking_rule text → shop_name, school_name, wifi_ssid id_card → passport, driver_license tag: a short, unique identifier (kebab_case, ≤ 30 chars) describing the item in context. Must be unique across all items. Include distinctive anchors (color, clothing, nearby object, text snippet). Example: blue-shopfront-haji-lane-sign, woman-white-shirt-face, red-sedan-rear-plate. reason: a short explanation (≤ 15 words). area: a concise description of the item’s location in the image, using relative position + anchors + optional text snippet. Example: upper-right on blue shopfront sign 'Haji Lane' Example: lower-center, woman in white shirt near green kiosk Area Description Guidance Always combine relative position (e.g., top-left, center-right) with anchors (clothing, colors, objects). Include legible text snippets (≤ 25 characters) when they differentiate objects. If multiple similar items exist, add stronger anchors to distinguish them. Use short, descriptive phrases (≈ 6–16 words). JSON Schema { sensitive_regions: [ { type: string, subtype: string (optional), tag: string, reason: string, area: string } ] } Negative Prompting Do not include coordinates, bounding boxes, sizes, or normalized values. Do not output anything outside the JSON (no prose, no Markdown). Do not use vague tags like face1, sign2; tags must be descriptive and unique. Do not hallucinate unreadable text; include text snippets only if clearly legible. Do not flag generic, non-sensitive text (e.g., SALE, OPEN). Do not duplicate the same object in multiple entries. Do not invent details beyond what the image supports. Do not miss any visible human faces — every distinct face must be flagged. Example Output { sensitive_regions: [ { type: face, tag: woman-white-shirt-face, reason: Identifiable human face, area: lower-center, woman in white shirt near green kiosk }, { type: street_sign, subtype: street_name, tag: blue-shopfront-haji-lane-sign, reason: Street name reveals location, area: upper-right on blue shopfront sign 'Haji Lane' }, { type: license_plate, tag: red-sedan-rear-plate, reason: Readable vehicle number, area: lower-center on red sedan rear plate }, { type: text, subtype: school_name, tag: navy-backpack-school-patch, reason: School name reveals identity, area: mid-right on navy backpack patch 'Temasek JC' } ] }"
          }
        ]
      }
    ],
    "generationConfig": {
      "temperature": 1.25,
      "thinkingConfig": {
        "thinkingBudget": -1
      }
    },
    "tools": [
      {
        "googleSearch": {
        }
      }
    ]
}